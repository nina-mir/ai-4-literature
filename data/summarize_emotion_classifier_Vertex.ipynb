{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1NU8seIk-6r9ac2VVSX7PgHLuePzUeB9A",
      "authorship_tag": "ABX9TyMXbrLuKm8knibL/GahGMg9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nina-mir/ai-4-literature/blob/main/data/summarize_emotion_classifier_Vertex.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMESWGrQCNUG",
        "outputId": "94814d8f-e78f-4f38-e9c3-7bb6bb638da1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: shapely<2.0.0 in /usr/local/lib/python3.10/dist-packages (1.8.5.post1)\n",
            "Requirement already satisfied: google-cloud-aiplatform in /usr/local/lib/python3.10/dist-packages (1.27.1)\n",
            "Requirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.11.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (1.22.3)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (3.20.3)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (23.1)\n",
            "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.8.0)\n",
            "Requirement already satisfied: google-cloud-bigquery<4.0.0dev,>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (3.10.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (1.10.2)\n",
            "Requirement already satisfied: shapely<2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (1.8.5.post1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.59.1)\n",
            "Requirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (2.17.3)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (2.27.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.56.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.48.2)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.3.2)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.5.0)\n",
            "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.8.2)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform) (0.12.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (4.9)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (3.4)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (0.5.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install \"shapely<2.0.0\"\n",
        "!pip install google-cloud-aiplatform"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "# import inspect module\n",
        "import inspect\n",
        "import itertools\n",
        "\n",
        "from google.colab import auth as google_auth\n",
        "google_auth.authenticate_user()\n",
        "\n",
        "import vertexai\n",
        "from vertexai.language_models import TextGenerationModel\n",
        "\n",
        "vertexai.init(project=\"ai-literature-392115\", location=\"us-central1\")\n",
        "parameters = {\n",
        "    \"temperature\": 0.9,\n",
        "    \"max_output_tokens\": 1024,\n",
        "    \"top_p\": 0.5,\n",
        "    \"top_k\": 40\n",
        "}\n",
        "model = TextGenerationModel.from_pretrained(\"text-bison@001\")\n",
        "\n",
        "# list of emotions\n",
        "emotions_str = \"\"\"Aflutter\tEmotional\tMelancholy\n",
        "Aloof\tEnthused\tMiffy\n",
        "Amusement\tErratic\tMoody\n",
        "Angry\tEuphoric\tMournful\n",
        "Antsy\tExcited\tMysterious\n",
        "Avid\tExhausted\tNervous\n",
        "Awe\tFamished\tNeurotic\n",
        "Bitter\tFearful\tNumb\n",
        "Blank\tFiery\tOminous\n",
        "Blue\tGloomy\tOn edge\n",
        "Calm\tGorged\tOrnery\n",
        "Cantankerous\tGormandizing\tPessimistic\n",
        "Capricious\tGratitude\tPetrified\n",
        "Cheerful\tGrim\tPetulant\n",
        "Chuffed\tGrumpy\tPride\n",
        "Colorless\tHesitant\tQueasy\n",
        "Covetous\tHollow\tRavenous\n",
        "Crabby\tHope\tReflective\n",
        "Cranky\tHopeless\tRestless\n",
        "Craving\tHumorous\tRomantic\n",
        "Cross\tIdyllic\tSerenity\n",
        "Deflated\tInconsolable\tSnappy\n",
        "Dejected\tInsatiable\tStarved\n",
        "Depressed\tInspiration\tTense\n",
        "Destitute\tInterest\tTouchy\n",
        "Devoid\tIrascible\tUnattached\n",
        "Devouring\tJittery\tUnpredictable\n",
        "Disheartening\tJumpy\tVacant\n",
        "Dispiriting\tLamentable\tVolatile\n",
        "Distant\tLighthearted\tVoracious\n",
        "Dither\tLivid\tWhimsical\n",
        "Drained\tLonely\tWorried\n",
        "Dyspeptic\tLove\tYearning\"\"\"\n",
        "emotions_comma = ','.join(list(emotions_str.split(\" \")))\n",
        "# uncomment this following line if you want to print out the list of emotions\n",
        "# print(\"list of emotions used in this work:\", emotions_comma)\n",
        "\n",
        "# taking care of the URL info\n",
        "with open(\"evergreen-urls.html\") as file:\n",
        "    list_urls = file.readlines()\n",
        "file.close()\n",
        "\n",
        "# input data file operation\n",
        "# open article-evergreen.json file\n",
        "with open(\"/content/articles-evergreen_cleaned_up.json\") as input:\n",
        "    data = json.load(input)\n",
        "\n",
        "# input.close()\n",
        "\n",
        "starting = 0\n",
        "ending = 10\n",
        "path_to_write = \"/content/backend_data_\" + str(starting)+\"_\"+str(ending)+\".json\"\n",
        "\n",
        "final_results=[]\n",
        "dict_item = {}\n",
        "\n",
        "for i in range(starting, ending):\n",
        "  item = data[i]\n",
        "  url = list_urls[i]\n",
        "  # for (item, url) in zip(data, list_urls):\n",
        "  # making a prompt from text variable above\n",
        "  prompt = \"\"\"Given a piece of text, classify the emotions it conveys, such as \"\"\" + emotions_comma + \"\"\" or anger up to three categories. Then, summarize the text.\n",
        "  text: \"\"\" + item[\"text\"]\n",
        "\n",
        "  response = model.predict(prompt, **parameters)\n",
        "\n",
        "  title = item[\"title\"]\n",
        "  url= url\n",
        "  time_2_read = item[\"time_2_read\"]\n",
        "  response = response.text\n",
        "\n",
        "  # a Python object (dict):\n",
        "  x = {\n",
        "    \"id\": i,\n",
        "    \"title\": item[\"title\"],\n",
        "    \"author\":item[\"author\"],\n",
        "    \"url\": url.strip(),\n",
        "    \"time_2_read\": item[\"time_2_read\"],\n",
        "    \"response\":response\n",
        "  }\n",
        "\n",
        "  final_results.append(x)\n",
        "\n",
        "\n",
        "# Write to a new json file the cleaned data\n",
        "with open(path_to_write, \"w\") as file_out:\n",
        "    json.dump(final_results, file_out)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "H7Mp3_VqC1oD"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 10-20\n",
        "\n",
        "starting = 10\n",
        "ending = 20\n",
        "path_to_write = \"/content/backend_data_\" + str(starting)+\"_\"+str(ending)+\".json\"\n",
        "\n",
        "final_results=[]\n",
        "dict_item = {}\n",
        "\n",
        "for i in range(starting, ending):\n",
        "  item = data[i]\n",
        "  url = list_urls[i]\n",
        "  # for (item, url) in zip(data, list_urls):\n",
        "  # making a prompt from text variable above\n",
        "  prompt = \"\"\"Given a piece of text, classify the emotions it conveys, such as \"\"\" + emotions_comma + \"\"\" or anger up to three categories. Then, summarize the text.\n",
        "  text: \"\"\" + item[\"text\"]\n",
        "\n",
        "  response = model.predict(prompt, **parameters)\n",
        "\n",
        "  title = item[\"title\"]\n",
        "  url= url\n",
        "  time_2_read = item[\"time_2_read\"]\n",
        "  response = response.text\n",
        "\n",
        "  # a Python object (dict):\n",
        "  x = {\n",
        "    \"id\": i,\n",
        "    \"title\": item[\"title\"],\n",
        "    \"author\":item[\"author\"],\n",
        "    \"url\": url.strip(),\n",
        "    \"time_2_read\": item[\"time_2_read\"],\n",
        "    \"response\":response\n",
        "  }\n",
        "\n",
        "  final_results.append(x)\n",
        "\n",
        "\n",
        "# Write to a new json file the cleaned data\n",
        "with open(path_to_write, \"w\") as file_out:\n",
        "    json.dump(final_results, file_out)\n"
      ],
      "metadata": {
        "id": "4nEHAvR_DpbS"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cQORcbaVJWIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 20-30\n",
        "\n",
        "starting = 20\n",
        "ending = 30\n",
        "path_to_write = \"/content/backend_data_\" + str(starting)+\"_\"+str(ending)+\".json\"\n",
        "\n",
        "final_results=[]\n",
        "dict_item = {}\n",
        "\n",
        "for i in range(starting, ending):\n",
        "  item = data[i]\n",
        "  url = list_urls[i]\n",
        "  # for (item, url) in zip(data, list_urls):\n",
        "  # making a prompt from text variable above\n",
        "  prompt = \"\"\"Given a piece of text, classify the emotions it conveys, such as \"\"\" + emotions_comma + \"\"\" or anger up to three categories. Then, summarize the text.\n",
        "  text: \"\"\" + item[\"text\"]\n",
        "\n",
        "  response = model.predict(prompt, **parameters)\n",
        "\n",
        "  title = item[\"title\"]\n",
        "  url= url\n",
        "  time_2_read = item[\"time_2_read\"]\n",
        "  response = response.text\n",
        "\n",
        "  # a Python object (dict):\n",
        "  x = {\n",
        "    \"id\": i,\n",
        "    \"title\": item[\"title\"],\n",
        "    \"author\":item[\"author\"],\n",
        "    \"url\": url.strip(),\n",
        "    \"time_2_read\": item[\"time_2_read\"],\n",
        "    \"response\":response\n",
        "  }\n",
        "\n",
        "  final_results.append(x)\n",
        "\n",
        "\n",
        "# Write to a new json file the cleaned data\n",
        "with open(path_to_write, \"w\") as file_out:\n",
        "    json.dump(final_results, file_out)\n"
      ],
      "metadata": {
        "id": "-3PRUVkgOX78"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8R6IHAEsKuF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 30-35\n",
        "\n",
        "starting = 30\n",
        "ending = 35\n",
        "path_to_write = \"/content/backend_data_\" + str(starting)+\"_\"+str(ending)+\".json\"\n",
        "\n",
        "final_results=[]\n",
        "dict_item = {}\n",
        "\n",
        "for i in range(starting, ending):\n",
        "  item = data[i]\n",
        "  url = list_urls[i]\n",
        "  # for (item, url) in zip(data, list_urls):\n",
        "  # making a prompt from text variable above\n",
        "  prompt = \"\"\"Given a piece of text, classify the emotions it conveys, such as \"\"\" + emotions_comma + \"\"\" or anger up to three categories. Then, summarize the text.\n",
        "  text: \"\"\" + item[\"text\"]\n",
        "\n",
        "  response = model.predict(prompt, **parameters)\n",
        "\n",
        "  title = item[\"title\"]\n",
        "  url= url\n",
        "  time_2_read = item[\"time_2_read\"]\n",
        "  response = response.text\n",
        "\n",
        "  # a Python object (dict):\n",
        "  x = {\n",
        "    \"id\": i,\n",
        "    \"title\": item[\"title\"],\n",
        "    \"author\":item[\"author\"],\n",
        "    \"url\": url.strip(),\n",
        "    \"time_2_read\": item[\"time_2_read\"],\n",
        "    \"response\":response\n",
        "  }\n",
        "\n",
        "  final_results.append(x)\n",
        "\n",
        "\n",
        "# Write to a new json file the cleaned data\n",
        "with open(path_to_write, \"w\") as file_out:\n",
        "    json.dump(final_results, file_out)\n"
      ],
      "metadata": {
        "id": "NQTCfc4fPtGY"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2S24yAjDQzu1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CciFzTgiQz6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 40-50\n",
        "\n",
        "starting = 40\n",
        "ending = 50\n",
        "path_to_write = \"/content/backend_data_\" + str(starting)+\"_\"+str(ending)+\".json\"\n",
        "\n",
        "final_results=[]\n",
        "dict_item = {}\n",
        "\n",
        "for i in range(starting, ending):\n",
        "  item = data[i]\n",
        "  url = list_urls[i]\n",
        "  # for (item, url) in zip(data, list_urls):\n",
        "  # making a prompt from text variable above\n",
        "  prompt = \"\"\"Given a piece of text, classify the emotions it conveys, such as \"\"\" + emotions_comma + \"\"\" or anger up to three categories. Then, summarize the text.\n",
        "  text: \"\"\" + item[\"text\"]\n",
        "\n",
        "  response = model.predict(prompt, **parameters)\n",
        "\n",
        "  title = item[\"title\"]\n",
        "  url= url\n",
        "  time_2_read = item[\"time_2_read\"]\n",
        "  response = response.text\n",
        "\n",
        "  # a Python object (dict):\n",
        "  x = {\n",
        "    \"id\": i,\n",
        "    \"title\": item[\"title\"],\n",
        "    \"author\":item[\"author\"],\n",
        "    \"url\": url.strip(),\n",
        "    \"time_2_read\": item[\"time_2_read\"],\n",
        "    \"response\":response\n",
        "  }\n",
        "\n",
        "  final_results.append(x)\n",
        "\n",
        "\n",
        "# Write to a new json file the cleaned data\n",
        "with open(path_to_write, \"w\") as file_out:\n",
        "    json.dump(final_results, file_out)\n"
      ],
      "metadata": {
        "id": "BRHv6hHXQ0BD"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "52PbhmhgRLcs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 50 -end\n",
        "\n",
        "starting = 50\n",
        "ending = len(data)\n",
        "path_to_write = \"/content/backend_data_\" + str(starting)+\"_\"+str(ending)+\".json\"\n",
        "\n",
        "final_results=[]\n",
        "dict_item = {}\n",
        "\n",
        "for i in range(starting, ending):\n",
        "  item = data[i]\n",
        "  url = list_urls[i]\n",
        "  # for (item, url) in zip(data, list_urls):\n",
        "  # making a prompt from text variable above\n",
        "  prompt = \"\"\"Given a piece of text, classify the emotions it conveys, such as \"\"\" + emotions_comma + \"\"\" or anger up to three categories. Then, summarize the text.\n",
        "  text: \"\"\" + item[\"text\"]\n",
        "\n",
        "  response = model.predict(prompt, **parameters)\n",
        "\n",
        "  title = item[\"title\"]\n",
        "  url= url\n",
        "  time_2_read = item[\"time_2_read\"]\n",
        "  response = response.text\n",
        "\n",
        "  # a Python object (dict):\n",
        "  x = {\n",
        "    \"id\": i,\n",
        "    \"title\": item[\"title\"],\n",
        "    \"author\":item[\"author\"],\n",
        "    \"url\": url.strip(),\n",
        "    \"time_2_read\": item[\"time_2_read\"],\n",
        "    \"response\":response\n",
        "  }\n",
        "\n",
        "  final_results.append(x)\n",
        "\n",
        "\n",
        "# Write to a new json file the cleaned data\n",
        "with open(path_to_write, \"w\") as file_out:\n",
        "    json.dump(final_results, file_out)\n"
      ],
      "metadata": {
        "id": "V75BVyRgRLsC"
      },
      "execution_count": 46,
      "outputs": []
    }
  ]
}